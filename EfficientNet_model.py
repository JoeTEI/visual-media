# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J_6dzYqVAekSjalUwSyZqLvrccuYFt27
"""

class Swish(nn.Module):
  def __init__(self):
    super().__init__()
  def forward(self, x):
    return x*torch.sigmoid(x)

class depth_wise_conv(nn.Module):
  def __init__(self, input_plane, kernel_size, stride, padding, bias=False):
    if padding!= kernel_size//2:
      print("check size error")
    super().__init__()
    self._depth_wise = nn.Conv2d(input_plane, input_plane, kernel_size, stride, padding, groups=input_plane,bias=bias)
    self._batch_norm = nn.BatchNorm2d(input_plane)
    self.act = Swish()

  def forward(self, x):
    out = self.act(self.BatchNorm(self._depth_wise(x)))
    return out

class pixel_wise_conv(nn.Module):
  def __init__(self, input_plane, output_plane, bias=False, act="swish"):
    super().__init__()
    self.depth_wise = nn.Conv2d(input_plane, output_plane, kernel_size=1, bias=bias)
    self.batch_norm = nn.BatchNorm2d(output_plane)
    if act=='swish':
      self.act = Swish()
    elif act is None:
      self.act = nn.Identity()

  def forward(self, x):
    out = self.act(self.batch_norm(self.depth_wise(x)))
    return out

class squeeze_excitation (nn.Module):
  def __init__(self, input_plane, h=8):
    super().__init__()
    self.GAP = nn.AdaptiveAvgPool2d(1) 
    self.FC1 = nn.Linear(input_plane, input_plane//h, bias=False) 
    self.act1 = Swish()
    self.FC2 = nn.Linear(input_plane//h, input_plane, bias=False)
    self.act2 = nn.Sigmoid()

  def forward(self, x):
    out = self.GAP(x).squeeze(-1).squeeze(-1)
    out = self.act1(self.funcc1(out))
    out = self.act2(self.funcc2(out)).unsqueeze(-1).unsqueeze(-1)
    return out*x


class MBConv(nn.Module):
  def __init__(self, input_plane, output_plane, kernel=5, stride=1, expansion=1):
    super().__init__()
    self.stride = stride
    self.input_plane = input_plane
    self.output_plane = output_plane
    self.pixel_wise1 = pixel_wise_conv(input_plane, input_plane*expansion, bias=False)
    self.depth_wise = depth_wise_conv(input_plane*expansion, kernel, stride, padding=kernel//2, bias=False)
    self.SE = squeeze_excitation(input_plane*expansion)
    self.pixel_wise2 = pixel_wise_conv(input_plane*expansion, output_plane, bias=False, act=None)

  def forward(self, x):
    out = self.pixel_wise2(self.se(self.depth_wise(self.pixel_wise1(x))))
    if self.stride == 1 and self.input_plane==self.output_plane:
      out = out+x
    return out

class EfficientNet(nn.Module):
  def __init__(self, n_c=3, n_classes=10):
    super().__init__()
    
    self.stage1 = nn.Sequential(
        nn.Conv2d(n_c,32,3,1,1,bias=False),
        nn.BatchNorm2d(32),
        Swish()
    )

    self.MBconv1 = MBConv(32, 16, 3, expansion=1)

    self.MBconv6_stage3 = nn.Sequential(
        MBConv(16, 24, kernel=3, stride=1, expansion=6),
        MBConv(24, 24, kernel=3, stride=1, expansion=6)
    )

    self.MBconv6_stage4 = nn.Sequential(
        MBConv(24, 40, kernel=5, stride=1, expansion=6),
        MBConv(40, 40, kernel=5, stride=1, expansion=6)
    )

    self.MBconv6_stage5 = nn.Sequential(
        MBConv(40, 80, kernel=3, stride=2, expansion=6),
        MBConv(80, 80, kernel=3, stride=1, expansion=6),
        MBConv(80, 80, kernel=3, stride=1, expansion=6),
    )

    self.MBconv6_stage6 = nn.Sequential(
        MBConv(80, 112, kernel=5, stride=1, expansion=6),
        MBConv(112, 112, kernel=5, stride=1, expansion=6),
        MBConv(112, 112, kernel=5, stride=1, expansion=6),
    )

    self.MBconv6_stage7 = nn.Sequential(
        MBConv(112, 192, kernel=5, stirde=2, expansion=6),
        MBConv(192, 192, kernel=5, stirde=1, expansion=6),
        MBConv(192, 192, kernel=5, stirde=1, expansion=6),
        MBConv(192, 192, kernel=5, stirde=1, expansion=6),
    )

    self.MBconv6_stage8 = nn.Sequential(
        MBConv(192, 320, kernel=3, stirde=1, expansion=6),
    )

    self.pixel_wise = pixel_wise_conv(320, 1280)
    self.GAP = nn.AdaptiveAvgPool2d(1)
    self.dropout = nn.Dropout(0.2)
    self.FC = nn.Linear(1280, n_classes)

  def forward(self, x):
    out = self.stage1(x)
    out = self.MBconv1(out)
    out = self.MBconv6_stage3(out)
    out = self.MBconv6_stage4(out)
    out = self.MBconv6_stage5(out)
    out = self.MBconv6_stage6(out)
    out = self.MBconv6_stage7(out)
    out = self.MBconv6_stage8(out)
    out = self.pixel_wise(out)
    out = self.GAP(out).view(x.size(0), -1)
    out = self.dropout(out)
    out = self.FC(out)
    return out